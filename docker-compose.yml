version: '3.8'

services:
  # Aplicaci√≥n de Scraping (solo Python)
  scraping_app:
    build: .
    container_name: scraping_app
    environment:
      - SQL_SERVER_HOST=${SQL_SERVER_HOST:-host.docker.internal\MSSQLSERVER01}
      - SQL_SERVER_PORT=${SQL_SERVER_PORT:-1433}
      - SQL_SERVER_DATABASE=${SQL_SERVER_DATABASE:-scraping_db}
      - SQL_SERVER_USERNAME=${SQL_SERVER_USERNAME:-}
      - SQL_SERVER_PASSWORD=${SQL_SERVER_PASSWORD:-}
      - SQL_SERVER_TRUSTED_CONNECTION=${SQL_SERVER_TRUSTED_CONNECTION:-yes}
      - RABBITMQ_HOST=${RABBITMQ_HOST:-rabbitmq_externo}
      - RABBITMQ_PORT=${RABBITMQ_PORT:-5672}
      - RABBITMQ_USERNAME=${RABBITMQ_USERNAME:-admin}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-admin123}
      - RABBITMQ_QUEUE=${RABBITMQ_QUEUE:-scraping_tasks}
      - RABBITMQ_EXCHANGE=${RABBITMQ_EXCHANGE:-aseguradora_exchange}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - SCRAPING_DELAY=${SCRAPING_DELAY:-2}
      - MAX_RETRIES=${MAX_RETRIES:-3}
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    # Conectar a red externa si es necesario
    # networks:
    #   - external_network
